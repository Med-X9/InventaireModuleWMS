#!/usr/bin/env python
"""
Test unitaire pour l'API CountingDetail avec 1000 lignes.
Ce script teste la performance et la robustesse de l'API counting-detail
en cr√©ant et validant 1000 CountingDetail avec diff√©rents sc√©narios.

Usage:
    python test_counting_detail_1000_lines.py

Auteur: Assistant IA
Date: 2024-12-15
"""

import os
import sys
import django
import requests
import json
import time
import random
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
import statistics

# Configuration Django
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'project.settings')
django.setup()

from django.contrib.auth import get_user_model
from django.test import TestCase
from django.urls import reverse
from rest_framework.test import APIClient
from rest_framework import status
from apps.inventory.models import Inventory, Counting, CountingDetail, NSerieInventory, Job, JobDetail, Assigment
from apps.masterdata.models import Product, Location, Warehouse, Account
from apps.users.models import User

User = get_user_model()


class CountingDetailPerformanceTest:
    """
    Classe de test de performance pour l'API CountingDetail.
    Teste la cr√©ation de 1000 CountingDetail avec diff√©rents sc√©narios.
    """
    
    def __init__(self):
        self.api_client = APIClient()
        self.base_url = "http://localhost:8000"
        self.api_base = f"{self.base_url}/mobile/api"
        self.test_user = None
        self.test_token = None
        self.test_data = {
            'accounts': [],
            'warehouses': [],
            'locations': [],
            'products': [],
            'inventories': [],
            'countings': [],
            'assignments': [],
            'jobs': [],
            'job_details': []
        }
        self.performance_metrics = {
            'creation_times': [],
            'response_times': [],
            'success_count': 0,
            'error_count': 0,
            'errors': []
        }
        
    def setUp(self):
        """Configuration initiale des donn√©es de test."""
        print("üîß Configuration initiale des donn√©es de test...")
        
        # Cr√©er un utilisateur de test
        self.test_user = User.objects.create_user(
            username='test_counting_user',
            email='test@example.com',
            password='testpass123'
        )
        
        # Obtenir le token d'authentification
        self._authenticate()
        
        # Cr√©er les donn√©es de base n√©cessaires
        self._create_base_data()
        
        print("‚úÖ Configuration termin√©e")
    
    def _authenticate(self):
        """Authentification et r√©cup√©ration du token."""
        try:
            # Utiliser l'API JWT pour l'authentification
            auth_data = {
                'username': 'test_counting_user',
                'password': 'testpass123'
            }
            
            response = requests.post(
                f"{self.api_base}/auth/jwt-login/",
                json=auth_data
            )
            
            if response.status_code == 200:
                self.test_token = response.json()['access_token']
                print("‚úÖ Authentification r√©ussie")
            else:
                print(f"‚ùå Erreur d'authentification: {response.text}")
                # Fallback: utiliser le client API Django pour les tests
                self.api_client.force_authenticate(user=self.test_user)
                
        except Exception as e:
            print(f"‚ùå Erreur d'authentification: {e}")
            # Utiliser le client API Django
            self.api_client.force_authenticate(user=self.test_user)
    
    def _create_base_data(self):
        """Cr√©e les donn√©es de base n√©cessaires pour les tests."""
        print("üì¶ Cr√©ation des donn√©es de base...")
        
        # Cr√©er des comptes
        for i in range(5):
            account = Account.objects.create(
                name=f"Test Account {i+1}",
                description=f"Compte de test {i+1}"
            )
            self.test_data['accounts'].append(account)
        
        # Cr√©er des entrep√¥ts
        for i, account in enumerate(self.test_data['accounts']):
            warehouse = Warehouse.objects.create(
                name=f"Test Warehouse {i+1}",
                account=account
            )
            self.test_data['warehouses'].append(warehouse)
        
        # Cr√©er des emplacements (200 emplacements)
        location_count = 0
        for warehouse in self.test_data['warehouses']:
            for j in range(40):  # 40 emplacements par entrep√¥t
                location = Location.objects.create(
                    name=f"LOC-{warehouse.name}-{j+1:03d}",
                    warehouse=warehouse
                )
                self.test_data['locations'].append(location)
                location_count += 1
        
        print(f"‚úÖ {location_count} emplacements cr√©√©s")
        
        # Les propri√©t√©s sont directement sur le mod√®le Product (n_lot, n_serie, dlc)
        
        # Cr√©er des produits (100 produits)
        for i in range(100):
            product = Product.objects.create(
                Internal_Product_Code=f"PROD-{i+1:05d}",
                Short_Description=f"Produit Test {i+1:03d}",
                Barcode=f"BAR-{i+1:08d}",
                Stock_Unit="Unit√©",
                Product_Status="ACTIVE",
                Product_Family=None,  # Vous pouvez cr√©er des familles si n√©cessaire
                n_lot=random.choice([True, False]),
                n_serie=random.choice([True, False]),
                dlc=random.choice([True, False])
            )
            self.test_data['products'].append(product)
        
        print(f"‚úÖ {len(self.test_data['products'])} produits cr√©√©s")
        
        # Cr√©er des inventaires (10 inventaires)
        for i in range(10):
            inventory = Inventory.objects.create(
                name=f"Inventaire Test {i+1}",
                account=random.choice(self.test_data['accounts']),
                warehouse=random.choice(self.test_data['warehouses'])
            )
            self.test_data['inventories'].append(inventory)
        
        # Cr√©er des comptages (30 comptages)
        count_modes = ["en vrac", "par article", "image de stock"]
        for i in range(30):
            counting = Counting.objects.create(
                order=i+1,
                count_mode=random.choice(count_modes),
                unit_scanned=random.choice([True, False]),
                entry_quantity=random.choice([True, False]),
                stock_situation=random.choice([True, False]),
                is_variant=random.choice([True, False]),
                n_lot=random.choice([True, False]),
                n_serie=random.choice([True, False]),
                dlc=random.choice([True, False]),
                show_product=random.choice([True, False]),
                quantity_show=random.choice([True, False]),
                inventory=random.choice(self.test_data['inventories'])
            )
            self.test_data['countings'].append(counting)
        
        print(f"‚úÖ {len(self.test_data['countings'])} comptages cr√©√©s")
        
        # Cr√©er des jobs et assignments
        for i in range(20):
            job = Job.objects.create(
                inventory=random.choice(self.test_data['inventories'])
            )
            self.test_data['jobs'].append(job)
            
            # Cr√©er des job details pour ce job
            selected_locations = random.sample(self.test_data['locations'], min(10, len(self.test_data['locations'])))
            for location in selected_locations:
                job_detail = JobDetail.objects.create(
                    location=location,
                    job=job,
                    counting=random.choice(self.test_data['countings']),
                    status='EN ATTENTE'
                )
                self.test_data['job_details'].append(job_detail)
            
            # Cr√©er un assignment
            assignment = Assigment.objects.create(
                job=job,
                user=self.test_user,
                status='EN COURS'
            )
            self.test_data['assignments'].append(assignment)
        
        print(f"‚úÖ {len(self.test_data['jobs'])} jobs et {len(self.test_data['assignments'])} assignments cr√©√©s")
        print(f"‚úÖ {len(self.test_data['job_details'])} job details cr√©√©s")
    
    def _generate_test_data(self, index: int) -> Dict[str, Any]:
        """G√©n√®re des donn√©es de test pour un CountingDetail."""
        counting = random.choice(self.test_data['countings'])
        location = random.choice(self.test_data['locations'])
        assignment = random.choice(self.test_data['assignments'])
        
        # Donn√©es de base
        data = {
            'counting_id': counting.id,
            'location_id': location.id,
            'quantity_inventoried': random.randint(1, 100),
            'assignment_id': assignment.id
        }
        
        # Ajouter product_id selon le mode de comptage
        if counting.count_mode == "par article":
            data['product_id'] = random.choice(self.test_data['products']).id
        elif random.choice([True, False]):  # 50% de chance pour les autres modes
            data['product_id'] = random.choice(self.test_data['products']).id
        
        # Ajouter DLC si n√©cessaire
        if counting.dlc or random.choice([True, False]):
            future_date = datetime.now() + timedelta(days=random.randint(30, 365))
            data['dlc'] = future_date.strftime('%Y-%m-%d')
        
        # Ajouter num√©ro de lot si n√©cessaire
        if counting.n_lot or random.choice([True, False]):
            data['n_lot'] = f"LOT-{index:05d}-{random.randint(1000, 9999)}"
        
        # Ajouter num√©ros de s√©rie si n√©cessaire
        if counting.n_serie and random.choice([True, False]):
            num_series = random.randint(1, min(5, data['quantity_inventoried']))
            data['numeros_serie'] = []
            for j in range(num_series):
                data['numeros_serie'].append({
                    'n_serie': f"NS-{index:05d}-{j+1:03d}-{random.randint(1000, 9999)}"
                })
        
        return data
    
    def _create_counting_detail_api(self, data: Dict[str, Any], index: int) -> Dict[str, Any]:
        """Cr√©e un CountingDetail via l'API REST."""
        start_time = time.time()
        
        try:
            headers = {}
            if self.test_token:
                headers['Authorization'] = f'Bearer {self.test_token}'
            
            if self.test_token:
                # Utiliser requests pour les appels HTTP
                response = requests.post(
                    f"{self.api_base}/counting-detail/",
                    json=data,
                    headers=headers
                )
                
                response_time = time.time() - start_time
                
                result = {
                    'index': index,
                    'status_code': response.status_code,
                    'response_time': response_time,
                    'success': response.status_code == 201,
                    'data': data
                }
                
                if response.status_code == 201:
                    result['response_data'] = response.json()
                else:
                    result['error'] = response.text
                    
            else:
                # Utiliser le client API Django
                response = self.api_client.post(
                    reverse('mobile:mobile_counting_detail'),
                    data,
                    format='json'
                )
                
                response_time = time.time() - start_time
                
                result = {
                    'index': index,
                    'status_code': response.status_code,
                    'response_time': response_time,
                    'success': response.status_code == 201,
                    'data': data
                }
                
                if response.status_code == 201:
                    result['response_data'] = response.data
                else:
                    result['error'] = str(response.data) if hasattr(response, 'data') else str(response.content)
            
            return result
            
        except Exception as e:
            response_time = time.time() - start_time
            return {
                'index': index,
                'status_code': 500,
                'response_time': response_time,
                'success': False,
                'error': str(e),
                'data': data
            }
    
    def _create_counting_detail_batch(self, start_index: int, count: int) -> List[Dict[str, Any]]:
        """Cr√©e un lot de CountingDetail."""
        results = []
        
        for i in range(count):
            index = start_index + i
            data = self._generate_test_data(index)
            result = self._create_counting_detail_api(data, index)
            results.append(result)
            
            # Affichage du progr√®s
            if (index + 1) % 50 == 0:
                print(f"  ‚úÖ {index + 1} CountingDetail trait√©s")
        
        return results
    
    def test_1000_counting_details_sequential(self):
        """Test s√©quentiel de cr√©ation de 1000 CountingDetail."""
        print("\nüöÄ Test s√©quentiel de 1000 CountingDetail...")
        print("=" * 60)
        
        start_time = time.time()
        all_results = []
        
        # Cr√©er 1000 CountingDetail de mani√®re s√©quentielle
        for i in range(1000):
            data = self._generate_test_data(i)
            result = self._create_counting_detail_api(data, i)
            all_results.append(result)
            
            # Mise √† jour des m√©triques
            if result['success']:
                self.performance_metrics['success_count'] += 1
                self.performance_metrics['creation_times'].append(result['response_time'])
            else:
                self.performance_metrics['error_count'] += 1
                self.performance_metrics['errors'].append({
                    'index': i,
                    'error': result.get('error', 'Unknown error'),
                    'data': result['data']
                })
            
            self.performance_metrics['response_times'].append(result['response_time'])
            
            # Affichage du progr√®s
            if (i + 1) % 100 == 0:
                print(f"  ‚úÖ {i + 1}/1000 CountingDetail trait√©s")
        
        total_time = time.time() - start_time
        
        print(f"\nüìä R√©sultats du test s√©quentiel:")
        print(f"  ‚Ä¢ Temps total: {total_time:.2f} secondes")
        print(f"  ‚Ä¢ Succ√®s: {self.performance_metrics['success_count']}/1000")
        print(f"  ‚Ä¢ Erreurs: {self.performance_metrics['error_count']}/1000")
        print(f"  ‚Ä¢ Temps moyen par requ√™te: {statistics.mean(self.performance_metrics['response_times']):.3f}s")
        print(f"  ‚Ä¢ Temps m√©dian par requ√™te: {statistics.median(self.performance_metrics['response_times']):.3f}s")
        
        if self.performance_metrics['creation_times']:
            print(f"  ‚Ä¢ Temps moyen de cr√©ation (succ√®s): {statistics.mean(self.performance_metrics['creation_times']):.3f}s")
        
        return all_results
    
    def test_1000_counting_details_parallel(self):
        """Test parall√®le de cr√©ation de 1000 CountingDetail."""
        print("\nüöÄ Test parall√®le de 1000 CountingDetail...")
        print("=" * 60)
        
        start_time = time.time()
        all_results = []
        
        # R√©initialiser les m√©triques
        self.performance_metrics = {
            'creation_times': [],
            'response_times': [],
            'success_count': 0,
            'error_count': 0,
            'errors': []
        }
        
        # Utiliser ThreadPoolExecutor pour les requ√™tes parall√®les
        with ThreadPoolExecutor(max_workers=10) as executor:
            # Diviser en lots de 100
            futures = []
            for batch_start in range(0, 1000, 100):
                batch_size = min(100, 1000 - batch_start)
                future = executor.submit(self._create_counting_detail_batch, batch_start, batch_size)
                futures.append(future)
            
            # Collecter les r√©sultats
            for future in as_completed(futures):
                try:
                    batch_results = future.result()
                    all_results.extend(batch_results)
                    
                    # Mise √† jour des m√©triques
                    for result in batch_results:
                        if result['success']:
                            self.performance_metrics['success_count'] += 1
                            self.performance_metrics['creation_times'].append(result['response_time'])
                        else:
                            self.performance_metrics['error_count'] += 1
                            self.performance_metrics['errors'].append({
                                'index': result['index'],
                                'error': result.get('error', 'Unknown error'),
                                'data': result['data']
                            })
                        
                        self.performance_metrics['response_times'].append(result['response_time'])
                        
                except Exception as e:
                    print(f"‚ùå Erreur dans le lot: {e}")
        
        total_time = time.time() - start_time
        
        print(f"\nüìä R√©sultats du test parall√®le:")
        print(f"  ‚Ä¢ Temps total: {total_time:.2f} secondes")
        print(f"  ‚Ä¢ Succ√®s: {self.performance_metrics['success_count']}/1000")
        print(f"  ‚Ä¢ Erreurs: {self.performance_metrics['error_count']}/1000")
        
        if self.performance_metrics['response_times']:
            print(f"  ‚Ä¢ Temps moyen par requ√™te: {statistics.mean(self.performance_metrics['response_times']):.3f}s")
            print(f"  ‚Ä¢ Temps m√©dian par requ√™te: {statistics.median(self.performance_metrics['response_times']):.3f}s")
            print(f"  ‚Ä¢ Temps min par requ√™te: {min(self.performance_metrics['response_times']):.3f}s")
            print(f"  ‚Ä¢ Temps max par requ√™te: {max(self.performance_metrics['response_times']):.3f}s")
        
        if self.performance_metrics['creation_times']:
            print(f"  ‚Ä¢ Temps moyen de cr√©ation (succ√®s): {statistics.mean(self.performance_metrics['creation_times']):.3f}s")
        
        return all_results
    
    def test_api_validation_scenarios(self):
        """Test des diff√©rents sc√©narios de validation."""
        print("\nüß™ Test des sc√©narios de validation...")
        print("=" * 60)
        
        validation_tests = [
            {
                'name': 'Donn√©es manquantes - counting_id',
                'data': {
                    'location_id': self.test_data['locations'][0].id,
                    'quantity_inventoried': 10,
                    'assignment_id': self.test_data['assignments'][0].id
                },
                'expected_status': 400
            },
            {
                'name': 'Donn√©es manquantes - location_id',
                'data': {
                    'counting_id': self.test_data['countings'][0].id,
                    'quantity_inventoried': 10,
                    'assignment_id': self.test_data['assignments'][0].id
                },
                'expected_status': 400
            },
            {
                'name': 'Quantit√© n√©gative',
                'data': {
                    'counting_id': self.test_data['countings'][0].id,
                    'location_id': self.test_data['locations'][0].id,
                    'quantity_inventoried': -5,
                    'assignment_id': self.test_data['assignments'][0].id
                },
                'expected_status': 400
            },
            {
                'name': 'Mode par article sans product_id',
                'data': {
                    'counting_id': next((c.id for c in self.test_data['countings'] if c.count_mode == "par article"), None),
                    'location_id': self.test_data['locations'][0].id,
                    'quantity_inventoried': 10,
                    'assignment_id': self.test_data['assignments'][0].id
                },
                'expected_status': 400
            }
        ]
        
        validation_results = []
        
        for i, test in enumerate(validation_tests):
            if test['data'].get('counting_id') is None:
                print(f"  ‚ö†Ô∏è Test '{test['name']}' ignor√© - pas de comptage appropri√©")
                continue
                
            print(f"  üß™ Test {i+1}: {test['name']}")
            
            result = self._create_counting_detail_api(test['data'], f"validation_{i}")
            
            validation_results.append({
                'test_name': test['name'],
                'expected_status': test['expected_status'],
                'actual_status': result['status_code'],
                'success': result['status_code'] == test['expected_status'],
                'error': result.get('error', '')
            })
            
            if result['status_code'] == test['expected_status']:
                print(f"    ‚úÖ Validation correcte (Status: {result['status_code']})")
            else:
                print(f"    ‚ùå Validation incorrecte (Attendu: {test['expected_status']}, Re√ßu: {result['status_code']})")
                print(f"    üìù Erreur: {result.get('error', 'Aucune erreur')}")
        
        # R√©sum√© des tests de validation
        successful_validations = sum(1 for r in validation_results if r['success'])
        print(f"\nüìä R√©sultats des tests de validation:")
        print(f"  ‚Ä¢ Tests r√©ussis: {successful_validations}/{len(validation_results)}")
        
        return validation_results
    
    def test_data_retrieval(self):
        """Test de r√©cup√©ration des donn√©es."""
        print("\nüì• Test de r√©cup√©ration des donn√©es...")
        print("=" * 60)
        
        # Cr√©er quelques CountingDetail pour les tests de r√©cup√©ration
        print("  üì¶ Cr√©ation de donn√©es de test pour la r√©cup√©ration...")
        test_counting = self.test_data['countings'][0]
        test_location = self.test_data['locations'][0]
        test_product = self.test_data['products'][0]
        
        # Cr√©er 5 CountingDetail pour les tests
        for i in range(5):
            data = {
                'counting_id': test_counting.id,
                'location_id': test_location.id,
                'quantity_inventoried': random.randint(1, 20),
                'assignment_id': self.test_data['assignments'][0].id,
                'product_id': test_product.id
            }
            self._create_counting_detail_api(data, f"retrieval_test_{i}")
        
        retrieval_tests = [
            {
                'name': 'R√©cup√©ration par counting_id',
                'url': f"{self.api_base}/counting-detail/?counting_id={test_counting.id}"
            },
            {
                'name': 'R√©cup√©ration par location_id',
                'url': f"{self.api_base}/counting-detail/?location_id={test_location.id}"
            },
            {
                'name': 'R√©cup√©ration par product_id',
                'url': f"{self.api_base}/counting-detail/?product_id={test_product.id}"
            }
        ]
        
        retrieval_results = []
        
        for test in retrieval_tests:
            print(f"  üîç {test['name']}")
            
            try:
                headers = {}
                if self.test_token:
                    headers['Authorization'] = f'Bearer {self.test_token}'
                
                start_time = time.time()
                
                if self.test_token:
                    response = requests.get(test['url'], headers=headers)
                    response_time = time.time() - start_time
                    
                    result = {
                        'test_name': test['name'],
                        'status_code': response.status_code,
                        'response_time': response_time,
                        'success': response.status_code == 200
                    }
                    
                    if response.status_code == 200:
                        data = response.json()
                        result['count'] = len(data.get('data', {}).get('counting_details', []))
                        print(f"    ‚úÖ {result['count']} √©l√©ments r√©cup√©r√©s en {response_time:.3f}s")
                    else:
                        result['error'] = response.text
                        print(f"    ‚ùå Erreur: {response.text}")
                else:
                    # Utiliser le client Django pour les tests
                    if 'counting_id' in test['url']:
                        response = self.api_client.get(
                            reverse('mobile:mobile_counting_detail'),
                            {'counting_id': test_counting.id}
                        )
                    elif 'location_id' in test['url']:
                        response = self.api_client.get(
                            reverse('mobile:mobile_counting_detail'),
                            {'location_id': test_location.id}
                        )
                    elif 'product_id' in test['url']:
                        response = self.api_client.get(
                            reverse('mobile:mobile_counting_detail'),
                            {'product_id': test_product.id}
                        )
                    
                    response_time = time.time() - start_time
                    
                    result = {
                        'test_name': test['name'],
                        'status_code': response.status_code,
                        'response_time': response_time,
                        'success': response.status_code == 200
                    }
                    
                    if response.status_code == 200:
                        result['count'] = len(response.data.get('data', {}).get('counting_details', []))
                        print(f"    ‚úÖ {result['count']} √©l√©ments r√©cup√©r√©s en {response_time:.3f}s")
                    else:
                        result['error'] = str(response.data) if hasattr(response, 'data') else str(response.content)
                        print(f"    ‚ùå Erreur: {result['error']}")
                
                retrieval_results.append(result)
                
            except Exception as e:
                print(f"    ‚ùå Exception: {e}")
                retrieval_results.append({
                    'test_name': test['name'],
                    'status_code': 500,
                    'success': False,
                    'error': str(e)
                })
        
        # R√©sum√© des tests de r√©cup√©ration
        successful_retrievals = sum(1 for r in retrieval_results if r['success'])
        print(f"\nüìä R√©sultats des tests de r√©cup√©ration:")
        print(f"  ‚Ä¢ Tests r√©ussis: {successful_retrievals}/{len(retrieval_results)}")
        
        return retrieval_results
    
    def generate_performance_report(self):
        """G√©n√®re un rapport de performance d√©taill√©."""
        print("\nüìä RAPPORT DE PERFORMANCE")
        print("=" * 80)
        
        # Statistiques g√©n√©rales
        if self.performance_metrics['response_times']:
            response_times = self.performance_metrics['response_times']
            creation_times = self.performance_metrics['creation_times']
            
            print(f"üéØ STATISTIQUES G√âN√âRALES:")
            print(f"  ‚Ä¢ Total de requ√™tes: {len(response_times)}")
            print(f"  ‚Ä¢ Succ√®s: {self.performance_metrics['success_count']}")
            print(f"  ‚Ä¢ Erreurs: {self.performance_metrics['error_count']}")
            print(f"  ‚Ä¢ Taux de succ√®s: {(self.performance_metrics['success_count']/len(response_times)*100):.1f}%")
            
            print(f"\n‚è±Ô∏è TEMPS DE R√âPONSE:")
            print(f"  ‚Ä¢ Temps moyen: {statistics.mean(response_times):.3f}s")
            print(f"  ‚Ä¢ Temps m√©dian: {statistics.median(response_times):.3f}s")
            print(f"  ‚Ä¢ Temps minimum: {min(response_times):.3f}s")
            print(f"  ‚Ä¢ Temps maximum: {max(response_times):.3f}s")
            print(f"  ‚Ä¢ √âcart type: {statistics.stdev(response_times):.3f}s")
            
            if creation_times:
                print(f"\n‚úÖ TEMPS DE CR√âATION (SUCC√àS UNIQUEMENT):")
                print(f"  ‚Ä¢ Temps moyen: {statistics.mean(creation_times):.3f}s")
                print(f"  ‚Ä¢ Temps m√©dian: {statistics.median(creation_times):.3f}s")
                print(f"  ‚Ä¢ Temps minimum: {min(creation_times):.3f}s")
                print(f"  ‚Ä¢ Temps maximum: {max(creation_times):.3f}s")
            
            # Analyse des percentiles
            sorted_times = sorted(response_times)
            p50 = sorted_times[int(len(sorted_times) * 0.5)]
            p90 = sorted_times[int(len(sorted_times) * 0.9)]
            p95 = sorted_times[int(len(sorted_times) * 0.95)]
            p99 = sorted_times[int(len(sorted_times) * 0.99)]
            
            print(f"\nüìà PERCENTILES DES TEMPS DE R√âPONSE:")
            print(f"  ‚Ä¢ P50 (m√©diane): {p50:.3f}s")
            print(f"  ‚Ä¢ P90: {p90:.3f}s")
            print(f"  ‚Ä¢ P95: {p95:.3f}s")
            print(f"  ‚Ä¢ P99: {p99:.3f}s")
        
        # Analyse des erreurs
        if self.performance_metrics['errors']:
            print(f"\n‚ùå ANALYSE DES ERREURS:")
            error_types = {}
            for error in self.performance_metrics['errors']:
                error_msg = error['error'][:100]  # Limiter la longueur
                error_types[error_msg] = error_types.get(error_msg, 0) + 1
            
            for error_msg, count in sorted(error_types.items(), key=lambda x: x[1], reverse=True):
                print(f"  ‚Ä¢ {error_msg}: {count} occurrences")
        
        # Recommandations de performance
        print(f"\nüîß RECOMMANDATIONS:")
        if self.performance_metrics['response_times']:
            avg_time = statistics.mean(self.performance_metrics['response_times'])
            if avg_time > 1.0:
                print(f"  ‚ö†Ô∏è Temps de r√©ponse √©lev√© ({avg_time:.3f}s). Consid√©rer l'optimisation.")
            elif avg_time > 0.5:
                print(f"  ‚ö° Temps de r√©ponse acceptable ({avg_time:.3f}s).")
            else:
                print(f"  üöÄ Excellent temps de r√©ponse ({avg_time:.3f}s)!")
        
        error_rate = self.performance_metrics['error_count'] / max(1, len(self.performance_metrics['response_times'])) * 100
        if error_rate > 10:
            print(f"  ‚ùå Taux d'erreur √©lev√© ({error_rate:.1f}%). V√©rifier la stabilit√© de l'API.")
        elif error_rate > 5:
            print(f"  ‚ö†Ô∏è Taux d'erreur mod√©r√© ({error_rate:.1f}%). Surveiller.")
        else:
            print(f"  ‚úÖ Faible taux d'erreur ({error_rate:.1f}%).")
    
    def cleanup(self):
        """Nettoyage des donn√©es de test."""
        print("\nüßπ Nettoyage des donn√©es de test...")
        
        try:
            # Supprimer les donn√©es cr√©√©es (dans l'ordre inverse des d√©pendances)
            CountingDetail.objects.filter(
                counting__inventory__name__startswith="Inventaire Test"
            ).delete()
            
            NSerieInventory.objects.filter(
                counting_detail__counting__inventory__name__startswith="Inventaire Test"
            ).delete()
            
            for model_list in [
                'job_details', 'assignments', 'jobs', 'countings', 
                'inventories', 'products', 'locations', 'warehouses', 'accounts'
            ]:
                for obj in self.test_data[model_list]:
                    try:
                        obj.delete()
                    except:
                        pass
            
            # Supprimer l'utilisateur de test
            if self.test_user:
                self.test_user.delete()
            
            print("‚úÖ Nettoyage termin√©")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur lors du nettoyage: {e}")
    
    def run_full_test_suite(self):
        """Ex√©cute la suite compl√®te de tests."""
        print("üöÄ D√âMARRAGE DE LA SUITE DE TESTS COUNTING DETAIL")
        print("=" * 80)
        print(f"üìÖ Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"üéØ Objectif: Tester 1000 cr√©ations de CountingDetail")
        print("=" * 80)
        
        try:
            # Configuration
            self.setUp()
            
            # Tests de validation
            validation_results = self.test_api_validation_scenarios()
            
            # Test de r√©cup√©ration
            retrieval_results = self.test_data_retrieval()
            
            # Test principal - 1000 CountingDetail (s√©quentiel)
            sequential_results = self.test_1000_counting_details_sequential()
            
            # Test principal - 1000 CountingDetail (parall√®le)
            parallel_results = self.test_1000_counting_details_parallel()
            
            # G√©n√©ration du rapport final
            self.generate_performance_report()
            
            print(f"\nüèÅ TESTS TERMIN√âS AVEC SUCC√àS!")
            print(f"üìä R√©sum√©:")
            print(f"  ‚Ä¢ Tests de validation: {len(validation_results)} ex√©cut√©s")
            print(f"  ‚Ä¢ Tests de r√©cup√©ration: {len(retrieval_results)} ex√©cut√©s")
            print(f"  ‚Ä¢ Tests de performance: 2000 CountingDetail cr√©√©s")
            print(f"  ‚Ä¢ Taux de succ√®s global: {(self.performance_metrics['success_count']/max(1, len(self.performance_metrics['response_times']))*100):.1f}%")
            
        except Exception as e:
            print(f"\n‚ùå ERREUR FATALE DANS LA SUITE DE TESTS: {e}")
            import traceback
            traceback.print_exc()
            
        finally:
            # Nettoyage
            self.cleanup()


def main():
    """Fonction principale."""
    print("üß™ TEST UNITAIRE COUNTING DETAIL - 1000 LIGNES")
    print("=" * 80)
    
    # Cr√©er et ex√©cuter les tests
    test_suite = CountingDetailPerformanceTest()
    test_suite.run_full_test_suite()


if __name__ == "__main__":
    main()
