# Test de Performance - API CountingDetail (1000 lignes)

## ğŸ“‹ Description

Ce test unitaire Ã©value la performance et la robustesse de l'API `counting-detail` en crÃ©ant et validant **1000 CountingDetail** avec diffÃ©rents scÃ©narios de test.

## ğŸš€ Utilisation

### Test complet (recommandÃ©)
```bash
python run_counting_detail_test.py
```

### Test rapide (100 Ã©lÃ©ments)
```bash
python run_counting_detail_test.py --quick
```

### Test personnalisÃ©
```bash
# Test avec 500 Ã©lÃ©ments
python run_counting_detail_test.py --count 500

# Test sÃ©quentiel avec 200 Ã©lÃ©ments
python run_counting_detail_test.py --count 200 --sequential

# Test sans validation
python run_counting_detail_test.py --count 300 --no-validation
```

### Test avancÃ© (script complet)
```bash
python test_counting_detail_1000_lines.py
```

## ğŸ“Š FonctionnalitÃ©s

### ğŸ§ª Tests inclus
- **Tests de validation** : VÃ©rification des rÃ¨gles de validation de l'API
- **Tests de performance** : CrÃ©ation de 1000 CountingDetail
- **Tests de rÃ©cupÃ©ration** : RÃ©cupÃ©ration des donnÃ©es par diffÃ©rents critÃ¨res
- **Tests parallÃ¨les** : ExÃ©cution simultanÃ©e pour mesurer la charge
- **Tests sÃ©quentiels** : ExÃ©cution sÃ©quentielle pour mesurer la latence

### ğŸ“ˆ MÃ©triques collectÃ©es
- Temps de rÃ©ponse (moyen, mÃ©dian, min, max)
- Taux de succÃ¨s/erreur
- DÃ©bit (requÃªtes/seconde)
- Percentiles (P50, P90, P95, P99)
- Analyse des erreurs

### ğŸ¯ ScÃ©narios testÃ©s
- **Mode "en vrac"** : Sans produit obligatoire
- **Mode "par article"** : Avec produit obligatoire
- **Mode "image de stock"** : Configuration mixte
- **NumÃ©ros de sÃ©rie** : CrÃ©ation avec numÃ©ros de sÃ©rie
- **PropriÃ©tÃ©s produits** : DLC, numÃ©ros de lot
- **Validation des donnÃ©es** : DonnÃ©es manquantes, invalides

## ğŸ—ï¸ Structure des donnÃ©es gÃ©nÃ©rÃ©es

### DonnÃ©es de base crÃ©Ã©es
- **5 comptes** (Account)
- **5 entrepÃ´ts** (Warehouse)
- **200 emplacements** (Location)
- **100 produits** (Product)
- **10 inventaires** (Inventory)
- **30 comptages** (Counting)
- **20 jobs et assignments**

### DonnÃ©es de test gÃ©nÃ©rÃ©es
- **1000 CountingDetail** avec propriÃ©tÃ©s variÃ©es
- **NumÃ©ros de sÃ©rie** alÃ©atoires
- **DLC et lots** selon les rÃ¨gles mÃ©tier
- **QuantitÃ©s** alÃ©atoires (1-100)

## ğŸ“‹ Exemple de donnÃ©es gÃ©nÃ©rÃ©es

```json
{
    "counting_id": 15,
    "location_id": 87,
    "quantity_inventoried": 25,
    "assignment_id": 12,
    "product_id": 43,
    "dlc": "2024-08-15",
    "n_lot": "LOT-00234-7891",
    "numeros_serie": [
        {"n_serie": "NS-00234-001-4567"},
        {"n_serie": "NS-00234-002-4568"}
    ]
}
```

## ğŸ“Š Exemple de rapport

```
ğŸ“Š RAPPORT DE PERFORMANCE
================================================================================
ğŸ¯ STATISTIQUES GÃ‰NÃ‰RALES:
  â€¢ Total de requÃªtes: 1000
  â€¢ SuccÃ¨s: 987
  â€¢ Erreurs: 13
  â€¢ Taux de succÃ¨s: 98.7%

â±ï¸ TEMPS DE RÃ‰PONSE:
  â€¢ Temps moyen: 0.245s
  â€¢ Temps mÃ©dian: 0.198s
  â€¢ Temps minimum: 0.089s
  â€¢ Temps maximum: 1.234s
  â€¢ Ã‰cart type: 0.156s

ğŸ“ˆ PERCENTILES DES TEMPS DE RÃ‰PONSE:
  â€¢ P50 (mÃ©diane): 0.198s
  â€¢ P90: 0.456s
  â€¢ P95: 0.678s
  â€¢ P99: 0.987s

ğŸ”§ RECOMMANDATIONS:
  âš¡ Temps de rÃ©ponse acceptable (0.245s).
  âœ… Faible taux d'erreur (1.3%).
```

## ğŸ”§ Configuration

### PrÃ©requis
- Django configurÃ©
- Base de donnÃ©es accessible
- API CountingDetail fonctionnelle
- Authentification JWT (optionnelle)

### Variables d'environnement
```bash
DJANGO_SETTINGS_MODULE=project.settings
```

### DÃ©pendances Python
- `django`
- `djangorestframework`
- `requests`
- `concurrent.futures`
- `statistics`

## ğŸ§¹ Nettoyage automatique

Le test effectue un nettoyage automatique :
- Suppression des CountingDetail crÃ©Ã©s
- Suppression des donnÃ©es de test
- Suppression de l'utilisateur de test
- Nettoyage des numÃ©ros de sÃ©rie

## âš¡ Optimisations

### Performance
- **RequÃªtes parallÃ¨les** : Utilisation de ThreadPoolExecutor
- **Lots optimisÃ©s** : Traitement par lots de 100 Ã©lÃ©ments
- **Gestion mÃ©moire** : Nettoyage automatique des donnÃ©es

### Monitoring
- **Temps rÃ©el** : Affichage du progrÃ¨s en temps rÃ©el
- **MÃ©triques dÃ©taillÃ©es** : Collecte de toutes les mÃ©triques importantes
- **Gestion d'erreurs** : Capture et analyse des erreurs

## ğŸ› DÃ©pannage

### Erreurs communes

#### Erreur d'authentification
```bash
# VÃ©rifier que l'API JWT fonctionne
curl -X POST http://localhost:8000/mobile/api/auth/jwt-login/ \
  -H "Content-Type: application/json" \
  -d '{"username": "test", "password": "test"}'
```

#### Erreur de base de donnÃ©es
```bash
# VÃ©rifier les migrations
python manage.py showmigrations
python manage.py migrate
```

#### Erreur de permissions
```bash
# VÃ©rifier les permissions de l'API
python manage.py shell
>>> from apps.mobile.views.counting.counting_detail_view import CountingDetailView
>>> print(CountingDetailView.permission_classes)
```

### Logs de dÃ©bogage

Le test gÃ©nÃ¨re des logs dÃ©taillÃ©s pour le dÃ©bogage :
- Temps de rÃ©ponse de chaque requÃªte
- DÃ©tails des erreurs rencontrÃ©es
- Statistiques en temps rÃ©el

## ğŸ“ˆ InterprÃ©tation des rÃ©sultats

### Temps de rÃ©ponse
- **< 0.2s** : Excellent
- **0.2-0.5s** : Bon
- **0.5-1.0s** : Acceptable
- **> 1.0s** : Ã€ optimiser

### Taux d'erreur
- **< 1%** : Excellent
- **1-5%** : Acceptable
- **5-10%** : Attention
- **> 10%** : ProblÃ©matique

### DÃ©bit
- **> 10 req/s** : Excellent
- **5-10 req/s** : Bon
- **2-5 req/s** : Acceptable
- **< 2 req/s** : Ã€ optimiser

## ğŸ”„ Ã‰volutions possibles

1. **Tests de charge** : Augmenter Ã  10 000 Ã©lÃ©ments
2. **Tests de stress** : Tester les limites du systÃ¨me
3. **Tests de rÃ©gression** : Comparer les performances dans le temps
4. **Monitoring continu** : IntÃ©gration avec des outils de monitoring
5. **Tests multi-utilisateurs** : Simulation de plusieurs utilisateurs simultanÃ©s

## ğŸ“ Support

Pour toute question ou problÃ¨me :
1. VÃ©rifier les logs Django
2. Consulter la documentation de l'API
3. Tester l'API manuellement avec cURL
4. VÃ©rifier la configuration de la base de donnÃ©es
